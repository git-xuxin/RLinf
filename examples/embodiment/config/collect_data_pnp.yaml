defaults:
  - env/realworld_bin_relocation@env.eval
  - override hydra/job_logging: stdout

hydra:
  run:
    dir: .
  output_subdir: null
  searchpath:
    - file://${oc.env:EMBODIED_PATH}/config/

cluster:
  num_nodes: 1
  component_placement:
    env:
      node_group: franka
      placement: 0
  node_groups:
    - label: franka
      node_ranks: 0
      hardware:
        type: Franka
        configs:
          - robot_ip: 172.16.0.2
            node_rank: 0
            camera_serials: ["213622078826"]  # third-person view
            # camera_serials: ["233622071437", "213622078826"]  # wrist camera, third-person view

runner:
  task_type: embodied
  logger:
    log_path: null
    project_name: rlinf
    experiment_name: "collect-data"
    logger_backends: ["tensorboard"] # wandb, swanlab
  num_data_episodes: 20
  record_task_description: False

env:
  group_name: "EnvGroup"
  eval:
    no_gripper: False
    ignore_terminations: False
    auto_reset: False
    keyboard_reward_wrapper: "multi_stage"  # 使用键盘给基础 reward
    use_spacemouse: True
    override_cfg:
      target_ee_pose: [0.564, 0.045, 0.05, -3.14, 0.0, 0.0]

# Reward 配置：键盘给基础 reward + 自动 gripper_penalty + time_penalty
reward:
  use_reward_model: False  # 不使用 reward model，用键盘
  
  # Gripper penalty configuration (from SERL PR 65)
  # 当 gripper 执行有效动作（状态改变）时施加惩罚
  enable_gripper_penalty: True
  gripper_penalty: 0.2
  binary_gripper_threshold: 0.5
  gripper_state_index: 0
  gripper_action_index: 6
  gripper_open_threshold: 0.04
  
  # Time penalty: 每步固定惩罚，鼓励更快完成任务
  time_penalty: -0.05